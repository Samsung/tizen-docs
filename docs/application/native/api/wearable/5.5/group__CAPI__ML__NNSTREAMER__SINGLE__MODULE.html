<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>Tizen Native API: Single</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen_html_stylesheet.css" rel="stylesheet" type="text/css" />
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
</script>
<link rel="search" href="search-opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="Tizen Native API"/>

</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">Tizen Native API
   &#160;<span id="projectnumber">5.5</span>
   </div>
   
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.7.6.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="dynsections.js"></script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>The&#160;Basics&#160;of&#160;Tizen&#160;Native&#160;API&#160;Reference</span></a></li>
      <li><a href="modules.html"><span>Native&#160;API&#160;Reference</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
          <div class="left">
            <form id="FSearchBox" action="search.php" method="get">
              <img id="MSearchSelect" src="search/mag.png" alt=""/>
              <input type="text" id="MSearchField" name="query" value="Search" size="20" accesskey="S" 
                     onfocus="searchBox.OnSearchFieldFocus(true)" 
                     onblur="searchBox.OnSearchFieldFocus(false)"/>
            </form>
          </div><div class="right"></div>
        </div>
      </li>
    </ul>
  </div>
</div>
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
  initNavTree('group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html','');
</script>
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#typedef-members">Typedefs</a>  </div>
  <div class="headertitle">
<div class="title">Single</div>  </div>
<div class="ingroups"><a class="el" href="group__CAPI__ML__FRAMEWORK.html">Machine Learning</a></div></div><!--header-->
<div class="contents">
<hr/><a name="details" id="details"></a><h2> </h2>
<p>The NNStreamer Single API provides interfaces to invoke a neural network model with a single instance of input data. </p>
<h2><a class="anchor" id="CAPI_ML_NNSTREAMER_SINGLE_HEADER"></a>
Required Header</h2>
<p>#include &lt;nnstreamer/nnstreamer-single.h&gt;<br/>
</p>
<h2><a class="anchor" id="CAPI_ML_NNSTREAMER_SINGLE_OVERVIEW"></a>
Overview</h2>
<p>The NNStreamer Single API provides interfaces to invoke a neural network model with a single instance of input data. This function is a syntactic sugar of NNStreamer Pipeline API with simplified features; thus, users are supposed to use NNStreamer Pipeline API directly if they want more advanced features. The user is expected to preprocess the input data for the given neural network model.</p>
<p>This function allows the following operations with NNStreamer:</p>
<ul>
<li>Open a machine learning model with various mechanisms.</li>
<li>Close the model.</li>
<li>Interfaces to enter a single instance of input data to the opened model.</li>
<li>Utility functions to get the information of opened model.</li>
</ul>
<p>Note that this function set is supposed to be thread-safe.</p>
<h2><a class="anchor" id="CAPI_ML_NNSTREAMER_SINGLE_FEATURE"></a>
Related Features</h2>
<p>This function is related with the following features:<br/>
</p>
<ul>
<li><a href="http://tizen.org/feature/machine_learning">http://tizen.org/feature/machine_learning</a><br/>
</li>
<li><a href="http://tizen.org/feature/machine_learning.inference">http://tizen.org/feature/machine_learning.inference</a><br/>
</li>
</ul>
<p>It is recommended to probe features in your application for reliability.<br/>
 You can check if a device supports the related features for this function by using <a class="el" href="group__CAPI__SYSTEM__SYSTEM__INFO__MODULE.html">System Information</a>, thereby controlling the procedure of your application.<br/>
 To ensure your application is only running on the device with specific features, please define the features in your manifest file using the manifest editor in the SDK.<br/>
 For example, your application accesses to the camera device, then you have to add '<a href="http://tizen.org/privilege/camera'">http://tizen.org/privilege/camera'</a> into the manifest of your application.<br/>
 More details on featuring your application can be found from <a href="https://docs.tizen.org/application/tizen-studio/native-tools/manifest-text-editor#feature-element"><b>Feature Element</b>. </a> </p>
<table class="memberdecls">
<tr><td colspan="2"><h2><a name="func-members"></a>
Functions</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gaeecad325c1c539fbaa6dfef102887ce2">ml_single_open</a> (<a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a> *single, const char *model, const <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga5f8d0255cd0b1aff41245b699ea65659">ml_tensors_info_h</a> input_info, const <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga5f8d0255cd0b1aff41245b699ea65659">ml_tensors_info_h</a> output_info, <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga5ad37edf81d9dfd5321d44b26f92c5a1">ml_nnfw_type_e</a> nnfw, <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#gae7921574e9d82aee3397c5651a1f42be">ml_nnfw_hw_e</a> hw)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Opens an ML model and returns the instance as a handle.  <a href="#gaeecad325c1c539fbaa6dfef102887ce2"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#ga4387f8dbcef5912015941670e2fc54ae">ml_single_close</a> (<a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a> single)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Closes the opened model handle.  <a href="#ga4387f8dbcef5912015941670e2fc54ae"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#ga6f5d2516a41dd1322b5c235b1cef040c">ml_single_invoke</a> (<a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a> single, const <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga67049dd89c4287044ee93839fa195fa2">ml_tensors_data_h</a> input, <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga67049dd89c4287044ee93839fa195fa2">ml_tensors_data_h</a> *output)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Invokes the model with the given input data.  <a href="#ga6f5d2516a41dd1322b5c235b1cef040c"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#ga692b722ca1133a3be6d7fab78aa81b69">ml_single_get_input_info</a> (<a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a> single, <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga5f8d0255cd0b1aff41245b699ea65659">ml_tensors_info_h</a> *info)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the information (tensor dimension, type, name and so on) of required input data for the given model.  <a href="#ga692b722ca1133a3be6d7fab78aa81b69"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#ga3335ea5bdc557d214515eca9014f3c6b">ml_single_get_output_info</a> (<a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a> single, <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga5f8d0255cd0b1aff41245b699ea65659">ml_tensors_info_h</a> *info)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Gets the information (tensor dimension, type, name and so on) of output data for the given model.  <a href="#ga3335ea5bdc557d214515eca9014f3c6b"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gaa6e3ecc31c6bfc189ec1c957edf4d3ad">ml_single_set_timeout</a> (<a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a> single, unsigned int timeout)</td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the maximum amount of time to wait for an output, in milliseconds.  <a href="#gaa6e3ecc31c6bfc189ec1c957edf4d3ad"></a><br/></td></tr>
<tr><td colspan="2"><h2><a name="typedef-members"></a>
Typedefs</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">typedef void *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a></td></tr>
<tr><td class="mdescLeft">&#160;</td><td class="mdescRight">A handle of a single-shot instance.  <a href="#gab87e8a2951a223f9471f01215fd3698a"></a><br/></td></tr>
</table>
<hr/><h2>Typedef Documentation</h2>
<a class="anchor" id="gab87e8a2951a223f9471f01215fd3698a"></a><!-- doxytag: member="nnstreamer&#45;single.h::ml_single_h" ref="gab87e8a2951a223f9471f01215fd3698a" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef void* <a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>A handle of a single-shot instance. </p>
<dl class="user"><dt><b>Since :</b></dt><dd>5.5 </dd></dl>

</div>
</div>
<hr/><h2>Function Documentation</h2>
<a class="anchor" id="ga4387f8dbcef5912015941670e2fc54ae"></a><!-- doxytag: member="nnstreamer&#45;single.h::ml_single_close" ref="ga4387f8dbcef5912015941670e2fc54ae" args="(ml_single_h single)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#ga4387f8dbcef5912015941670e2fc54ae">ml_single_close</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a>&#160;</td>
          <td class="paramname"><em>single</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Closes the opened model handle. </p>
<dl class="user"><dt><b>Since :</b></dt><dd>5.5 </dd></dl>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">single</td><td>The model handle to be closed. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd><code>0</code> on success. Otherwise a negative error value. </dd></dl>
<dl class="retval"><dt><b>Return values:</b></dt><dd>
  <table class="retval">
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a1d5fc7f826e7a67851245a3f27b7d0a7">ML_ERROR_NONE</a></td><td>Successful </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93aabfd19c4f0472a012e00204cf076ed66">ML_ERROR_NOT_SUPPORTED</a></td><td>Not supported. </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a8081833f5d75604414cd5cb831c538ab">ML_ERROR_INVALID_PARAMETER</a></td><td>Fail. The parameter is invalid (Pipeline is not negotiated yet.) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga692b722ca1133a3be6d7fab78aa81b69"></a><!-- doxytag: member="nnstreamer&#45;single.h::ml_single_get_input_info" ref="ga692b722ca1133a3be6d7fab78aa81b69" args="(ml_single_h single, ml_tensors_info_h *info)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#ga692b722ca1133a3be6d7fab78aa81b69">ml_single_get_input_info</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a>&#160;</td>
          <td class="paramname"><em>single</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga5f8d0255cd0b1aff41245b699ea65659">ml_tensors_info_h</a> *&#160;</td>
          <td class="paramname"><em>info</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Gets the information (tensor dimension, type, name and so on) of required input data for the given model. </p>
<p>Note that a model may not have such information if its input type is flexible. The name of tensors are sometimes unavailable (optional), while its dimensions and types are always available. </p>
<dl class="user"><dt><b>Since :</b></dt><dd>5.5 </dd></dl>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">single</td><td>The model handle. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">info</td><td>The handle of input tensors information. The caller is responsible for freeing the information with <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#gaec4bae5d600139d335826612109c2b9e" title="Frees the given handle of a tensors information.">ml_tensors_info_destroy()</a>. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd><code>0</code> on success. Otherwise a negative error value. </dd></dl>
<dl class="retval"><dt><b>Return values:</b></dt><dd>
  <table class="retval">
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a1d5fc7f826e7a67851245a3f27b7d0a7">ML_ERROR_NONE</a></td><td>Successful </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93aabfd19c4f0472a012e00204cf076ed66">ML_ERROR_NOT_SUPPORTED</a></td><td>Not supported. </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a8081833f5d75604414cd5cb831c538ab">ML_ERROR_INVALID_PARAMETER</a></td><td>Fail. The parameter is invalid. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga3335ea5bdc557d214515eca9014f3c6b"></a><!-- doxytag: member="nnstreamer&#45;single.h::ml_single_get_output_info" ref="ga3335ea5bdc557d214515eca9014f3c6b" args="(ml_single_h single, ml_tensors_info_h *info)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#ga3335ea5bdc557d214515eca9014f3c6b">ml_single_get_output_info</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a>&#160;</td>
          <td class="paramname"><em>single</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga5f8d0255cd0b1aff41245b699ea65659">ml_tensors_info_h</a> *&#160;</td>
          <td class="paramname"><em>info</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Gets the information (tensor dimension, type, name and so on) of output data for the given model. </p>
<p>Note that a model may not have such information if its output type is flexible and output type is not determined statically. The name of tensors are sometimes unavailable (optional), while its dimensions and types are always available. </p>
<dl class="user"><dt><b>Since :</b></dt><dd>5.5 </dd></dl>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">single</td><td>The model handle. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">info</td><td>The handle of output tensors information. The caller is responsible for freeing the information with <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#gaec4bae5d600139d335826612109c2b9e" title="Frees the given handle of a tensors information.">ml_tensors_info_destroy()</a>. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd><code>0</code> on success. Otherwise a negative error value. </dd></dl>
<dl class="retval"><dt><b>Return values:</b></dt><dd>
  <table class="retval">
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a1d5fc7f826e7a67851245a3f27b7d0a7">ML_ERROR_NONE</a></td><td>Successful </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93aabfd19c4f0472a012e00204cf076ed66">ML_ERROR_NOT_SUPPORTED</a></td><td>Not supported. </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a8081833f5d75604414cd5cb831c538ab">ML_ERROR_INVALID_PARAMETER</a></td><td>Fail. The parameter is invalid. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga6f5d2516a41dd1322b5c235b1cef040c"></a><!-- doxytag: member="nnstreamer&#45;single.h::ml_single_invoke" ref="ga6f5d2516a41dd1322b5c235b1cef040c" args="(ml_single_h single, const ml_tensors_data_h input, ml_tensors_data_h *output)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#ga6f5d2516a41dd1322b5c235b1cef040c">ml_single_invoke</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a>&#160;</td>
          <td class="paramname"><em>single</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga67049dd89c4287044ee93839fa195fa2">ml_tensors_data_h</a>&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga67049dd89c4287044ee93839fa195fa2">ml_tensors_data_h</a> *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Invokes the model with the given input data. </p>
<p>Even if the model has flexible input data dimensions, input data frames of an instance of a model should share the same dimension. Note that this has a default timeout of 3 seconds. If an application wants to change the time to wait for an output, set the timeout using <a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gaa6e3ecc31c6bfc189ec1c957edf4d3ad" title="Sets the maximum amount of time to wait for an output, in milliseconds.">ml_single_set_timeout()</a>. </p>
<dl class="user"><dt><b>Since :</b></dt><dd>5.5 </dd></dl>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">single</td><td>The model handle to be inferred. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input</td><td>The input data to be inferred. </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>The allocated output buffer. The caller is responsible for freeing the output buffer with <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga46ea2e374a99dda84abdedcd2274491f" title="Frees the given tensors&#39; data handle.">ml_tensors_data_destroy()</a>. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd><code>0</code> on success. Otherwise a negative error value. </dd></dl>
<dl class="retval"><dt><b>Return values:</b></dt><dd>
  <table class="retval">
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a1d5fc7f826e7a67851245a3f27b7d0a7">ML_ERROR_NONE</a></td><td>Successful </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93aabfd19c4f0472a012e00204cf076ed66">ML_ERROR_NOT_SUPPORTED</a></td><td>Not supported. </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a8081833f5d75604414cd5cb831c538ab">ML_ERROR_INVALID_PARAMETER</a></td><td>Fail. The parameter is invalid. </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a17a8d71c54b9508ca0167419985e65d4">ML_ERROR_STREAMS_PIPE</a></td><td>Cannot push a buffer into source element. </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93aaf6fc53860088c1be29d98cf24240015">ML_ERROR_TIMED_OUT</a></td><td>Failed to get the result from sink element. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gaeecad325c1c539fbaa6dfef102887ce2"></a><!-- doxytag: member="nnstreamer&#45;single.h::ml_single_open" ref="gaeecad325c1c539fbaa6dfef102887ce2" args="(ml_single_h *single, const char *model, const ml_tensors_info_h input_info, const ml_tensors_info_h output_info, ml_nnfw_type_e nnfw, ml_nnfw_hw_e hw)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gaeecad325c1c539fbaa6dfef102887ce2">ml_single_open</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a> *&#160;</td>
          <td class="paramname"><em>single</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const char *&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga5f8d0255cd0b1aff41245b699ea65659">ml_tensors_info_h</a>&#160;</td>
          <td class="paramname"><em>input_info</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga5f8d0255cd0b1aff41245b699ea65659">ml_tensors_info_h</a>&#160;</td>
          <td class="paramname"><em>output_info</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ga5ad37edf81d9dfd5321d44b26f92c5a1">ml_nnfw_type_e</a>&#160;</td>
          <td class="paramname"><em>nnfw</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#gae7921574e9d82aee3397c5651a1f42be">ml_nnfw_hw_e</a>&#160;</td>
          <td class="paramname"><em>hw</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Opens an ML model and returns the instance as a handle. </p>
<p>Even if the model has flexible input data dimensions, input data frames of an instance of a model should share the same dimension. </p>
<dl class="user"><dt><b>Since :</b></dt><dd>5.5 </dd></dl>
<dl class="remark"><dt><b>Remarks:</b></dt><dd><a href="http://tizen.org/privilege/mediastorage">http://tizen.org/privilege/mediastorage</a> is needed if <em>model</em> is relevant to media storage. </dd>
<dd>
<a href="http://tizen.org/privilege/externalstorage">http://tizen.org/privilege/externalstorage</a> is needed if <em>model</em> is relevant to external storage. </dd></dl>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramdir">[out]</td><td class="paramname">single</td><td>This is the model handle opened. Users are required to close the given instance with <a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#ga4387f8dbcef5912015941670e2fc54ae" title="Closes the opened model handle.">ml_single_close()</a>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">model</td><td>This is the path to the neural network model file. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_info</td><td>This is required if the given model has flexible input dimension, where the input dimension MUST be given before executing the model. However, once it's given, the input dimension cannot be changed for the given model handle. It is required by some custom filters of NNStreamer. You may set NULL if it's not required. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_info</td><td>This is required if the given model has flexible output dimension. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">nnfw</td><td>The neural network framework used to open the given <em>model</em>. Set <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#gga5ad37edf81d9dfd5321d44b26f92c5a1a416e6cb597e323613fb266f31d09763e">ML_NNFW_TYPE_ANY</a> to let it auto-detect. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">hw</td><td>Tell the corresponding <em>nnfw</em> to use a specific hardware. Set <a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggae7921574e9d82aee3397c5651a1f42bea94de4d7470eb3a258e590ee11fc77db1">ML_NNFW_HW_ANY</a> if it does not matter. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd><code>0</code> on success. Otherwise a negative error value. </dd></dl>
<dl class="retval"><dt><b>Return values:</b></dt><dd>
  <table class="retval">
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a1d5fc7f826e7a67851245a3f27b7d0a7">ML_ERROR_NONE</a></td><td>Successful </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93aabfd19c4f0472a012e00204cf076ed66">ML_ERROR_NOT_SUPPORTED</a></td><td>Not supported. </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a8081833f5d75604414cd5cb831c538ab">ML_ERROR_INVALID_PARAMETER</a></td><td>Fail. The parameter is invalid. </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a17a8d71c54b9508ca0167419985e65d4">ML_ERROR_STREAMS_PIPE</a></td><td>Failed to start the pipeline. </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a39df68b9a816c7c276768edacf3a9b8e">ML_ERROR_PERMISSION_DENIED</a></td><td>The application does not have the privilege to access to the media storage or external storage. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gaa6e3ecc31c6bfc189ec1c957edf4d3ad"></a><!-- doxytag: member="nnstreamer&#45;single.h::ml_single_set_timeout" ref="gaa6e3ecc31c6bfc189ec1c957edf4d3ad" args="(ml_single_h single, unsigned int timeout)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gaa6e3ecc31c6bfc189ec1c957edf4d3ad">ml_single_set_timeout</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group__CAPI__ML__NNSTREAMER__SINGLE__MODULE.html#gab87e8a2951a223f9471f01215fd3698a">ml_single_h</a>&#160;</td>
          <td class="paramname"><em>single</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">unsigned int&#160;</td>
          <td class="paramname"><em>timeout</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Sets the maximum amount of time to wait for an output, in milliseconds. </p>
<dl class="user"><dt><b>Since :</b></dt><dd>5.5 </dd></dl>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">single</td><td>The model handle. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">timeout</td><td>The time to wait for an output. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd><code>0</code> on success. Otherwise a negative error value. </dd></dl>
<dl class="retval"><dt><b>Return values:</b></dt><dd>
  <table class="retval">
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a1d5fc7f826e7a67851245a3f27b7d0a7">ML_ERROR_NONE</a></td><td>Successful </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93aabfd19c4f0472a012e00204cf076ed66">ML_ERROR_NOT_SUPPORTED</a></td><td>Not supported. </td></tr>
    <tr><td class="paramname"><a class="el" href="group__CAPI__ML__NNSTREAMER__PIPELINE__MODULE.html#ggafa8aa7b8ee0794aff8dcd3029525fc93a8081833f5d75604414cd5cb831c538ab">ML_ERROR_INVALID_PARAMETER</a></td><td>Fail. The parameter is invalid. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
</div><!-- contents -->
</div>
  <div id="nav-path" class="navpath">
    <ul>
<hr size="1"/>
<center>
<small>Except as noted, this content - excluding the Code Examples - is licensed under <a href="http://creativecommons.org/licenses/by/3.0/legalcode" target="_blank">Creative Commons Attribution 3.0</a>
and all of the Code Examples contained herein are licensed under <a href="https://www.tizen.org/bsd-3-clause-license" target="_blank">BSD-3-Clause</a>.<br/>For details, see the <a href="https://www.tizen.org/content-license" target="_blank">Content License</a>.&nbsp;</small>
</center>
</body>
</html>
